{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b97bc36",
   "metadata": {},
   "source": [
    "# SEMANA 1 - FUNDAÃ‡ÃƒO DA REPRODUTIBILIDADE\n",
    "\n",
    "**Dataset:** Titanic (train_final.csv)  \n",
    "**Objetivo:** Preparar terreno confiÃ¡vel antes de treinar\n",
    "\n",
    "Este notebook estabelece a fundaÃ§Ã£o do projeto:\n",
    "- âœ… Fixar seeds para reprodutibilidade\n",
    "- âœ… Criar estrutura de pastas\n",
    "- âœ… Realizar split estratificado 80/20\n",
    "- âœ… Salvar Ã­ndices para reuso futuro\n",
    "- âœ… Gerar documentaÃ§Ã£o do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d521a",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Importar Bibliotecas\n",
    "\n",
    "ImportaÃ§Ã£o de todas as bibliotecas necessÃ¡rias para setup do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58588bd",
   "metadata": {},
   "source": [
    "## ğŸ² 1. Fixar Seeds (Reprodutibilidade)\n",
    "\n",
    "**Por que isso Ã© crucial?**\n",
    "- Redes neurais usam inicializaÃ§Ã£o aleatÃ³ria de pesos\n",
    "- Train/test split Ã© aleatÃ³rio\n",
    "- Dropout Ã© aleatÃ³rio durante treino\n",
    "\n",
    "Fixando a seed = **mesmos resultados em mÃºltiplas execuÃ§Ãµes**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24798f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"âœ… Seeds fixadas! SEED =\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd455c",
   "metadata": {},
   "source": [
    "## ğŸ“ 2. Criar Estrutura de Pastas\n",
    "\n",
    "OrganizaÃ§Ã£o padronizada do projeto para facilitar manutenÃ§Ã£o e reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6151b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pastas = [\n",
    "    'data/raw',\n",
    "    'data/processed', \n",
    "    'splits',\n",
    "    'artifacts',\n",
    "    'reports',\n",
    "    'reports/figures',\n",
    "    'src',\n",
    "    'notebooks'\n",
    "]\n",
    "\n",
    "for pasta in pastas:\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "    \n",
    "print(\"âœ… Estrutura de pastas criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff196b27",
   "metadata": {},
   "source": [
    "## ğŸ“Š 3. Carregar Dataset\n",
    "\n",
    "Carregamos o `train_final.csv` que jÃ¡ foi preprocessado com o script `normalize.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset preprocessado\n",
    "df = pd.read_csv('../data/train_final.csv')\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset carregado:\")\n",
    "print(f\"   - Total de amostras: {len(df)}\")\n",
    "print(f\"   - Features: {df.shape[1] - 1}\")  # -1 por causa do target 'Survived'\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d728d",
   "metadata": {},
   "source": [
    "## ğŸ¯ 4. Separar Features (X) e Target (y)\n",
    "\n",
    "Separamos as features da variÃ¡vel target (`Survived`) e analisamos a distribuiÃ§Ã£o das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c261f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar features (X) e target (y)\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "print(f\"\\nğŸ¯ DistribuiÃ§Ã£o das classes:\")\n",
    "print(f\"   - Morreu (0): {(y==0).sum()} ({(y==0).sum()/len(y)*100:.1f}%)\")\n",
    "print(f\"   - Sobreviveu (1): {(y==1).sum()} ({(y==1).sum()/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4b4bc",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ 5. Split Estratificado (80/20)\n",
    "\n",
    "**Por que estratificado?**\n",
    "- Dataset desbalanceado (~62% morreu, ~38% sobreviveu)\n",
    "- EstratificaÃ§Ã£o mantÃ©m a **mesma proporÃ§Ã£o** de classes no treino e validaÃ§Ã£o\n",
    "- Evita que validaÃ§Ã£o tenha distribuiÃ§Ã£o diferente do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.20,           # 20% para validaÃ§Ã£o\n",
    "    stratify=y,               # ESTRATIFICADO! MantÃ©m proporÃ§Ã£o das classes\n",
    "    random_state=SEED         # Seed para reprodutibilidade\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ‚ï¸ Split estratificado realizado (80/20):\")\n",
    "print(f\"   TREINO: {len(X_train)} amostras\")\n",
    "print(f\"   VAL:    {len(X_val)} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5289fa2f",
   "metadata": {},
   "source": [
    "## âœ… 6. Verificar EstratificaÃ§Ã£o\n",
    "\n",
    "Confirmamos que as proporÃ§Ãµes de classes sÃ£o mantidas em ambos os conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nâœ… Verificando estratificaÃ§Ã£o:\")\n",
    "print(f\"   TREINO - Morreu: {(y_train==0).sum()/len(y_train)*100:.1f}%, Sobreviveu: {(y_train==1).sum()/len(y_train)*100:.1f}%\")\n",
    "print(f\"   VAL    - Morreu: {(y_val==0).sum()/len(y_val)*100:.1f}%, Sobreviveu: {(y_val==1).sum()/len(y_val)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9f492",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 7. Salvar Ãndices dos Splits\n",
    "\n",
    "**CRÃTICO PARA REPRODUTIBILIDADE!**\n",
    "\n",
    "Salvamos os Ã­ndices exatos do split para que todas as semanas usem **exatamente os mesmos dados** de treino e validaÃ§Ã£o. Isso garante que possamos comparar diferentes arquiteturas de forma justa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar Ã­ndices do split para usar nas prÃ³ximas semanas\n",
    "train_indices = X_train.index.tolist()\n",
    "val_indices = X_val.index.tolist()\n",
    "\n",
    "splits_info = {\n",
    "    'seed': SEED,\n",
    "    'train_size': len(train_indices),\n",
    "    'val_size': len(val_indices),\n",
    "    'train_indices': train_indices,\n",
    "    'val_indices': val_indices,\n",
    "    'train_class_distribution': {\n",
    "        'class_0': int((y_train==0).sum()),\n",
    "        'class_1': int((y_train==1).sum())\n",
    "    },\n",
    "    'val_class_distribution': {\n",
    "        'class_0': int((y_val==0).sum()),\n",
    "        'class_1': int((y_val==1).sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar em JSON\n",
    "with open('../splits/split_indices.json', 'w') as f:\n",
    "    json.dump(splits_info, f, indent=4)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Ãndices salvos em: splits/split_indices.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a485e",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 8. Salvar Datasets Separados\n",
    "\n",
    "Salvamos os datasets jÃ¡ separados para facilitar o carregamento nas prÃ³ximas semanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os datasets jÃ¡ separados\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_val.to_csv('../data/processed/y_val.csv', index=False)\n",
    "\n",
    "print(f\"ğŸ’¾ Datasets separados salvos em: data/processed/\")\n",
    "print(f\"   - X_train.csv: {X_train.shape}\")\n",
    "print(f\"   - X_val.csv: {X_val.shape}\")\n",
    "print(f\"   - y_train.csv: {y_train.shape}\")\n",
    "print(f\"   - y_val.csv: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2dcdab",
   "metadata": {},
   "source": [
    "## ğŸ“ 9. Criar DocumentaÃ§Ã£o do Projeto\n",
    "\n",
    "Geramos README.md e requirements.txt para documentar o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a47afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_content = \"\"\"# Projeto Titanic - Machine Learning\n",
    "\n",
    "## Objetivo\n",
    "Treinar redes neurais (MLPs e Ensembles) para prever sobrevivÃªncia no Titanic.\n",
    "\n",
    "## Dataset\n",
    "- **Fonte:** train_final.csv (preprocessado)\n",
    "- **Amostras:** 891\n",
    "- **Features:** 15 (jÃ¡ normalizadas 0-1)\n",
    "- **Target:** Survived (0=morreu, 1=sobreviveu)\n",
    "\n",
    "## DistribuiÃ§Ã£o das Classes\n",
    "- Morreu (0): ~62%\n",
    "- Sobreviveu (1): ~38%\n",
    "\n",
    "## Reprodutibilidade\n",
    "- **SEED:** 42 (fixada em todos os scripts)\n",
    "- **Split:** 80% treino / 20% validaÃ§Ã£o (estratificado)\n",
    "- **Ãndices salvos em:** `splits/split_indices.json`\n",
    "\n",
    "## Como Reproduzir\n",
    "\n",
    "### 1. Preparar ambiente (Semana 1)\n",
    "```bash\n",
    "jupyter notebook notebooks/semana1_setup.ipynb\n",
    "```\n",
    "\n",
    "Isso cria:\n",
    "- Estrutura de pastas\n",
    "- Split estratificado (80/20)\n",
    "- Salva Ã­ndices para reuso\n",
    "- Datasets separados em `data/processed/`\n",
    "\n",
    "### 2. Verificar splits\n",
    "Os mesmos Ã­ndices serÃ£o usados em TODAS as semanas para garantir comparabilidade!\n",
    "\n",
    "## Estrutura de Pastas\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/              # Dados originais\n",
    "â”‚   â””â”€â”€ processed/        # X_train, X_val, y_train, y_val\n",
    "â”œâ”€â”€ splits/               # Ãndices dos splits\n",
    "â”œâ”€â”€ artifacts/            # Modelos treinados, pipelines\n",
    "â”œâ”€â”€ reports/              # Resultados, mÃ©tricas\n",
    "â”‚   â””â”€â”€ figures/          # GrÃ¡ficos\n",
    "â”œâ”€â”€ src/                  # Scripts Python\n",
    "â””â”€â”€ notebooks/            # Jupyter notebooks\n",
    "```\n",
    "\n",
    "## PrÃ³ximos Passos\n",
    "- **Semana 2:** Planejar hiperparÃ¢metros\n",
    "- **Semana 3:** Treinar MLP 1\n",
    "- **Semana 4:** AnÃ¡lise de mÃ©tricas\n",
    "- **Semana 5:** K-fold validation\n",
    "\n",
    "## Arquiteturas Propostas\n",
    "Ver documento: `docs/4_propostas_arquiteturas_titanic.md`\n",
    "\"\"\"\n",
    "\n",
    "with open('../projeto_README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"ğŸ“ projeto_README.md criado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7cc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = \"\"\"numpy==1.24.3\n",
    "pandas==2.0.3\n",
    "scikit-learn==1.3.0\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "tensorflow==2.13.0\n",
    "keras==2.13.1\n",
    "\"\"\"\n",
    "\n",
    "with open('../projeto_requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(f\"ğŸ“ projeto_requirements.txt criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1029659",
   "metadata": {},
   "source": [
    "## ğŸ‰ RESUMO FINAL\n",
    "\n",
    "Tudo pronto para comeÃ§ar o treinamento das redes neurais!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ SEMANA 1 COMPLETA - FUNDAÃ‡ÃƒO DA REPRODUTIBILIDADE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "âœ… Seeds fixadas (SEED={SEED})\n",
    "âœ… Estrutura de pastas criada\n",
    "âœ… Split estratificado 80/20\n",
    "âœ… Ãndices salvos (splits/split_indices.json)\n",
    "âœ… Datasets separados (data/processed/)\n",
    "âœ… projeto_README.md criado\n",
    "âœ… projeto_requirements.txt criado\n",
    "\n",
    "ğŸ¯ PRÃ“XIMO PASSO: Semana 2 - Planejar hiperparÃ¢metros da MLP 1\n",
    "\n",
    "ğŸ“Š EstatÃ­sticas do Split:\n",
    "   - Treino: {len(X_train)} amostras\n",
    "   - ValidaÃ§Ã£o: {len(X_val)} amostras\n",
    "   - Features: {X_train.shape[1]}\n",
    "   \n",
    "ğŸ“ Arquivos Gerados:\n",
    "   - splits/split_indices.json\n",
    "   - data/processed/X_train.csv\n",
    "   - data/processed/X_val.csv\n",
    "   - data/processed/y_train.csv\n",
    "   - data/processed/y_val.csv\n",
    "   - projeto_README.md\n",
    "   - projeto_requirements.txt\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
