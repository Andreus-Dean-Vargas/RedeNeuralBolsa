{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b97bc36",
   "metadata": {},
   "source": [
    "# SEMANA 1 - FUNDA√á√ÉO DA REPRODUTIBILIDADE\n",
    "\n",
    "**Dataset:** Titanic (train_final.csv)  \n",
    "**Objetivo:** Preparar terreno confi√°vel antes de treinar\n",
    "\n",
    "Este notebook estabelece a funda√ß√£o do projeto:\n",
    "- ‚úÖ Fixar seeds para reprodutibilidade\n",
    "- ‚úÖ Criar estrutura de pastas\n",
    "- ‚úÖ Realizar split estratificado 80/20\n",
    "- ‚úÖ Salvar √≠ndices para reuso futuro\n",
    "- ‚úÖ Gerar documenta√ß√£o do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d521a",
   "metadata": {},
   "source": [
    "## üì¶ Importar Bibliotecas\n",
    "\n",
    "Importa√ß√£o de todas as bibliotecas necess√°rias para setup do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f40f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58588bd",
   "metadata": {},
   "source": [
    "## üé≤ 1. Fixar Seeds (Reprodutibilidade)\n",
    "\n",
    "**Por que isso √© crucial?**\n",
    "- Redes neurais usam inicializa√ß√£o aleat√≥ria de pesos\n",
    "- Train/test split √© aleat√≥rio\n",
    "- Dropout √© aleat√≥rio durante treino\n",
    "\n",
    "Fixando a seed = **mesmos resultados em m√∫ltiplas execu√ß√µes**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24798f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Seeds fixadas! SEED = 42\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"‚úÖ Seeds fixadas! SEED =\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd455c",
   "metadata": {},
   "source": [
    "## üìÅ 2. Criar Estrutura de Pastas\n",
    "\n",
    "Organiza√ß√£o padronizada do projeto para facilitar manuten√ß√£o e reprodutibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6151b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Estrutura de pastas criada!\n"
     ]
    }
   ],
   "source": [
    "pastas = [\n",
    "    '../data/raw',\n",
    "    '../data/processed', \n",
    "    '../splits',\n",
    "    '../artifacts',\n",
    "    '../reports',\n",
    "    '../reports/figures',\n",
    "    '../src',\n",
    "    '.'  # notebooks (pasta atual)\n",
    "]\n",
    "\n",
    "for pasta in pastas:\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "    \n",
    "print(\"‚úÖ Estrutura de pastas criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff196b27",
   "metadata": {},
   "source": [
    "## üìä 3. Carregar Dataset\n",
    "\n",
    "Carregamos o `train_final.csv` que j√° foi preprocessado com o script `normalize.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909b36ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Dataset carregado:\n",
      "   - Total de amostras: 891\n",
      "   - Features: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>HasCabin</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>FamilySize_1</th>\n",
       "      <th>FamilySize_2</th>\n",
       "      <th>FamilySize_3</th>\n",
       "      <th>FamilySize_4</th>\n",
       "      <th>FamilySize_5plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex   Age      Fare  HasCabin  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0         0    0  0.22  0.000142         0         0         0         1   \n",
       "1         1    1  0.38  0.139136         1         1         0         0   \n",
       "2         1    1  0.26  0.001547         0         0         0         1   \n",
       "3         1    1  0.35  0.000104         1         1         0         0   \n",
       "4         0    0  0.35  0.000157         1         0         0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  FamilySize_1  FamilySize_2  \\\n",
       "0           0           0           1             0             1   \n",
       "1           1           0           0             0             1   \n",
       "2           0           0           1             1             0   \n",
       "3           0           0           1             0             1   \n",
       "4           0           0           1             1             0   \n",
       "\n",
       "   FamilySize_3  FamilySize_4  FamilySize_5plus  \n",
       "0             0             0                 0  \n",
       "1             0             0                 0  \n",
       "2             0             0                 0  \n",
       "3             0             0                 0  \n",
       "4             0             0                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega o dataset preprocessado\n",
    "df = pd.read_csv('../data/train_final.csv')\n",
    "\n",
    "print(f\"\\nüìä Dataset carregado:\")\n",
    "print(f\"   - Total de amostras: {len(df)}\")\n",
    "print(f\"   - Features: {df.shape[1] - 1}\")  # -1 por causa do target 'Survived'\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d728d",
   "metadata": {},
   "source": [
    "## üéØ 4. Separar Features (X) e Target (y)\n",
    "\n",
    "Separamos as features da vari√°vel target (`Survived`) e analisamos a distribui√ß√£o das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c261f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Distribui√ß√£o das classes:\n",
      "   - Morreu (0): 549 (61.6%)\n",
      "   - Sobreviveu (1): 342 (38.4%)\n"
     ]
    }
   ],
   "source": [
    "# Separar features (X) e target (y)\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "print(f\"\\nüéØ Distribui√ß√£o das classes:\")\n",
    "print(f\"   - Morreu (0): {(y==0).sum()} ({(y==0).sum()/len(y)*100:.1f}%)\")\n",
    "print(f\"   - Sobreviveu (1): {(y==1).sum()} ({(y==1).sum()/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4b4bc",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è 5. Split Estratificado (80/20)\n",
    "\n",
    "**Por que estratificado?**\n",
    "- Dataset desbalanceado (~62% morreu, ~38% sobreviveu)\n",
    "- Estratifica√ß√£o mant√©m a **mesma propor√ß√£o** de classes no treino e valida√ß√£o\n",
    "- Evita que valida√ß√£o tenha distribui√ß√£o diferente do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad9bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÇÔ∏è Split estratificado realizado (80/20):\n",
      "   TREINO: 712 amostras\n",
      "   VAL:    179 amostras\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.20,           # 20% para valida√ß√£o\n",
    "    stratify=y,               # ESTRATIFICADO! Mant√©m propor√ß√£o das classes\n",
    "    random_state=SEED         # Seed para reprodutibilidade\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è Split estratificado realizado (80/20):\")\n",
    "print(f\"   TREINO: {len(X_train)} amostras\")\n",
    "print(f\"   VAL:    {len(X_val)} amostras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5289fa2f",
   "metadata": {},
   "source": [
    "## ‚úÖ 6. Verificar Estratifica√ß√£o\n",
    "\n",
    "Confirmamos que as propor√ß√µes de classes s√£o mantidas em ambos os conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037f7602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Verificando estratifica√ß√£o:\n",
      "   TREINO - Morreu: 61.7%, Sobreviveu: 38.3%\n",
      "   VAL    - Morreu: 61.5%, Sobreviveu: 38.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n‚úÖ Verificando estratifica√ß√£o:\")\n",
    "print(f\"   TREINO - Morreu: {(y_train==0).sum()/len(y_train)*100:.1f}%, Sobreviveu: {(y_train==1).sum()/len(y_train)*100:.1f}%\")\n",
    "print(f\"   VAL    - Morreu: {(y_val==0).sum()/len(y_val)*100:.1f}%, Sobreviveu: {(y_val==1).sum()/len(y_val)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9f492",
   "metadata": {},
   "source": [
    "## üíæ 7. Salvar √çndices dos Splits\n",
    "\n",
    "**CR√çTICO PARA REPRODUTIBILIDADE!**\n",
    "\n",
    "Salvamos os √≠ndices exatos do split para que todas as semanas usem **exatamente os mesmos dados** de treino e valida√ß√£o. Isso garante que possamos comparar diferentes arquiteturas de forma justa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beee31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ √çndices salvos em: splits/split_indices.json\n"
     ]
    }
   ],
   "source": [
    "# Salvar √≠ndices do split para usar nas pr√≥ximas semanas\n",
    "train_indices = X_train.index.tolist()\n",
    "val_indices = X_val.index.tolist()\n",
    "\n",
    "splits_info = {\n",
    "    'seed': SEED,\n",
    "    'train_size': len(train_indices),\n",
    "    'val_size': len(val_indices),\n",
    "    'train_indices': train_indices,\n",
    "    'val_indices': val_indices,\n",
    "    'train_class_distribution': {\n",
    "        'class_0': int((y_train==0).sum()),\n",
    "        'class_1': int((y_train==1).sum())\n",
    "    },\n",
    "    'val_class_distribution': {\n",
    "        'class_0': int((y_val==0).sum()),\n",
    "        'class_1': int((y_val==1).sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar em JSON\n",
    "with open('../splits/split_indices.json', 'w') as f:\n",
    "    json.dump(splits_info, f, indent=4)\n",
    "\n",
    "print(f\"\\nüíæ √çndices salvos em: splits/split_indices.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a485e",
   "metadata": {},
   "source": [
    "## üíæ 8. Salvar Datasets Separados\n",
    "\n",
    "Salvamos os datasets j√° separados para facilitar o carregamento nas pr√≥ximas semanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a64e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Datasets separados salvos em: data/processed/\n",
      "   - X_train.csv: (712, 15)\n",
      "   - X_val.csv: (179, 15)\n",
      "   - y_train.csv: (712,)\n",
      "   - y_val.csv: (179,)\n"
     ]
    }
   ],
   "source": [
    "# Salvar os datasets j√° separados\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_val.to_csv('../data/processed/y_val.csv', index=False)\n",
    "\n",
    "print(f\"üíæ Datasets separados salvos em: data/processed/\")\n",
    "print(f\"   - X_train.csv: {X_train.shape}\")\n",
    "print(f\"   - X_val.csv: {X_val.shape}\")\n",
    "print(f\"   - y_train.csv: {y_train.shape}\")\n",
    "print(f\"   - y_val.csv: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2dcdab",
   "metadata": {},
   "source": [
    "## üìù 9. Criar Documenta√ß√£o do Projeto\n",
    "\n",
    "Geramos README.md e requirements.txt para documentar o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0a47afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù projeto_README.md criado!\n"
     ]
    }
   ],
   "source": [
    "readme_content = \"\"\"# Projeto Titanic - Machine Learning\n",
    "\n",
    "## Objetivo\n",
    "Treinar redes neurais (MLPs e Ensembles) para prever sobreviv√™ncia no Titanic.\n",
    "\n",
    "## Dataset\n",
    "- **Fonte:** train_final.csv (preprocessado)\n",
    "- **Amostras:** 891\n",
    "- **Features:** 15 (j√° normalizadas 0-1)\n",
    "- **Target:** Survived (0=morreu, 1=sobreviveu)\n",
    "\n",
    "## Distribui√ß√£o das Classes\n",
    "- Morreu (0): ~62%\n",
    "- Sobreviveu (1): ~38%\n",
    "\n",
    "## Reprodutibilidade\n",
    "- **SEED:** 42 (fixada em todos os scripts)\n",
    "- **Split:** 80% treino / 20% valida√ß√£o (estratificado)\n",
    "- **√çndices salvos em:** `splits/split_indices.json`\n",
    "\n",
    "## Como Reproduzir\n",
    "\n",
    "### 1. Preparar ambiente (Semana 1)\n",
    "```bash\n",
    "jupyter notebook notebooks/semana1_setup.ipynb\n",
    "```\n",
    "\n",
    "Isso cria:\n",
    "- Estrutura de pastas\n",
    "- Split estratificado (80/20)\n",
    "- Salva √≠ndices para reuso\n",
    "- Datasets separados em `data/processed/`\n",
    "\n",
    "### 2. Verificar splits\n",
    "Os mesmos √≠ndices ser√£o usados em TODAS as semanas para garantir comparabilidade!\n",
    "\n",
    "## Estrutura de Pastas\n",
    "```\n",
    ".\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Dados originais\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/        # X_train, X_val, y_train, y_val\n",
    "‚îú‚îÄ‚îÄ splits/               # √çndices dos splits\n",
    "‚îú‚îÄ‚îÄ artifacts/            # Modelos treinados, pipelines\n",
    "‚îú‚îÄ‚îÄ reports/              # Resultados, m√©tricas\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ figures/          # Gr√°ficos\n",
    "‚îú‚îÄ‚îÄ src/                  # Scripts Python\n",
    "‚îî‚îÄ‚îÄ notebooks/            # Jupyter notebooks\n",
    "```\n",
    "\n",
    "## Pr√≥ximos Passos\n",
    "- **Semana 2:** Planejar hiperpar√¢metros\n",
    "- **Semana 3:** Treinar MLP 1\n",
    "- **Semana 4:** An√°lise de m√©tricas\n",
    "- **Semana 5:** K-fold validation\n",
    "\n",
    "## Arquiteturas Propostas\n",
    "Ver documento: `docs/4_propostas_arquiteturas_titanic.md`\n",
    "\"\"\"\n",
    "\n",
    "with open('../projeto_README.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"üìù projeto_README.md criado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee7cc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù projeto_requirements.txt criado!\n"
     ]
    }
   ],
   "source": [
    "requirements = \"\"\"numpy==1.24.3\n",
    "pandas==2.0.3\n",
    "scikit-learn==1.3.0\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "tensorflow==2.13.0\n",
    "keras==2.13.1\n",
    "\"\"\"\n",
    "\n",
    "with open('../projeto_requirements.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(f\"üìù projeto_requirements.txt criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1029659",
   "metadata": {},
   "source": [
    "## üéâ RESUMO FINAL\n",
    "\n",
    "Tudo pronto para come√ßar o treinamento das redes neurais!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8259b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ SEMANA 1 COMPLETA - FUNDA√á√ÉO DA REPRODUTIBILIDADE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Seeds fixadas (SEED=42)\n",
      "‚úÖ Estrutura de pastas criada\n",
      "‚úÖ Split estratificado 80/20\n",
      "‚úÖ √çndices salvos (splits/split_indices.json)\n",
      "‚úÖ Datasets separados (data/processed/)\n",
      "‚úÖ projeto_README.md criado\n",
      "‚úÖ projeto_requirements.txt criado\n",
      "\n",
      "üéØ PR√ìXIMO PASSO: Semana 2 - Planejar hiperpar√¢metros da MLP 1\n",
      "\n",
      "üìä Estat√≠sticas do Split:\n",
      "   - Treino: 712 amostras\n",
      "   - Valida√ß√£o: 179 amostras\n",
      "   - Features: 15\n",
      "\n",
      "üìÅ Arquivos Gerados:\n",
      "   - splits/split_indices.json\n",
      "   - data/processed/X_train.csv\n",
      "   - data/processed/X_val.csv\n",
      "   - data/processed/y_train.csv\n",
      "   - data/processed/y_val.csv\n",
      "   - projeto_README.md\n",
      "   - projeto_requirements.txt\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ SEMANA 1 COMPLETA - FUNDA√á√ÉO DA REPRODUTIBILIDADE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "‚úÖ Seeds fixadas (SEED={SEED})\n",
    "‚úÖ Estrutura de pastas criada\n",
    "‚úÖ Split estratificado 80/20\n",
    "‚úÖ √çndices salvos (splits/split_indices.json)\n",
    "‚úÖ Datasets separados (data/processed/)\n",
    "‚úÖ projeto_README.md criado\n",
    "‚úÖ projeto_requirements.txt criado\n",
    "\n",
    "üéØ PR√ìXIMO PASSO: Semana 2 - Planejar hiperpar√¢metros da MLP 1\n",
    "\n",
    "üìä Estat√≠sticas do Split:\n",
    "   - Treino: {len(X_train)} amostras\n",
    "   - Valida√ß√£o: {len(X_val)} amostras\n",
    "   - Features: {X_train.shape[1]}\n",
    "   \n",
    "üìÅ Arquivos Gerados:\n",
    "   - splits/split_indices.json\n",
    "   - data/processed/X_train.csv\n",
    "   - data/processed/X_val.csv\n",
    "   - data/processed/y_train.csv\n",
    "   - data/processed/y_val.csv\n",
    "   - projeto_README.md\n",
    "   - projeto_requirements.txt\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
