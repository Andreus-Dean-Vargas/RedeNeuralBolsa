{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e20f1b",
   "metadata": {},
   "source": [
    "# SEMANA 2 - MLP 1 MINIMALISTA\n",
    "\n",
    "**Arquitetura:** Input(15) ‚Üí Dense(16, ReLU) ‚Üí Output(1, Sigmoid)  \n",
    "**Par√¢metros:** 273 (rela√ß√£o 3.26 amostras/par√¢metro - SEGURO!)\n",
    "\n",
    "## Objetivos desta semana:\n",
    "1. ‚úÖ Carregar dados preprocessados (Semana 1)\n",
    "2. ‚úÖ Implementar arquitetura MLP 1\n",
    "3. ‚úÖ Definir hiperpar√¢metros (learning rate, batch size, epochs)\n",
    "4. ‚úÖ Treinar modelo com callbacks (EarlyStopping, ModelCheckpoint)\n",
    "5. ‚úÖ Avaliar performance (acur√°cia, loss, curvas de aprendizado)\n",
    "6. ‚úÖ Salvar modelo e m√©tricas\n",
    "\n",
    "## Por que esta arquitetura?\n",
    "- **Simples e interpret√°vel** - apenas 1 camada oculta\n",
    "- **Baixo risco de overfitting** - 273 par√¢metros para 712 amostras de treino\n",
    "- **Baseline s√≥lido** - captura padr√µes principais sem decorar ru√≠dos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d2315",
   "metadata": {},
   "source": [
    "## üì¶ Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(f\"TensorFlow vers√£o: {tf.__version__}\")\n",
    "print(f\"Keras vers√£o: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e6871",
   "metadata": {},
   "source": [
    "## üé≤ Fixar Seeds (Reprodutibilidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Fixar seeds\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"‚úÖ Seeds fixadas! SEED =\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429ad77",
   "metadata": {},
   "source": [
    "## üìÇ Carregar Dados (Semana 1)\n",
    "\n",
    "Carregamos os dados j√° separados e os √≠ndices salvos na Semana 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar datasets separados\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_val = pd.read_csv('../data/processed/X_val.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
    "y_val = pd.read_csv('../data/processed/y_val.csv').values.ravel()\n",
    "\n",
    "# Carregar informa√ß√µes do split\n",
    "with open('../splits/split_indices.json', 'r') as f:\n",
    "    split_info = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Dados carregados:\")\n",
    "print(f\"   - X_train: {X_train.shape}\")\n",
    "print(f\"   - X_val: {X_val.shape}\")\n",
    "print(f\"   - y_train: {y_train.shape}\")\n",
    "print(f\"   - y_val: {y_val.shape}\")\n",
    "print(f\"\\nüìä Distribui√ß√£o (treino): Classe 0={split_info['train_class_distribution']['class_0']}, Classe 1={split_info['train_class_distribution']['class_1']}\")\n",
    "print(f\"üìä Distribui√ß√£o (val): Classe 0={split_info['val_class_distribution']['class_0']}, Classe 1={split_info['val_class_distribution']['class_1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1beab",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Definir Arquitetura MLP 1\n",
    "\n",
    "**Estrutura:**\n",
    "```\n",
    "Input (15) ‚Üí Dense(16, ReLU) + Dropout(0.2) + L2(0.01) ‚Üí Output(1, Sigmoid)\n",
    "```\n",
    "\n",
    "**Contagem de par√¢metros:**\n",
    "- Camada 1: 15 √ó 16 + 16 (bias) = **256 par√¢metros**\n",
    "- Camada 2: 16 √ó 1 + 1 (bias) = **17 par√¢metros**\n",
    "- **TOTAL: 273 par√¢metros**\n",
    "\n",
    "**Rela√ß√£o:** 712 amostras / 273 params = **2.61 amostras por par√¢metro** ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_mlp1(input_dim=15, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    MLP 1 - Minimalista\n",
    "    Input(15) ‚Üí Dense(16, ReLU) ‚Üí Output(1, Sigmoid)\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(16, activation='relu', \n",
    "              input_dim=input_dim,\n",
    "              kernel_regularizer=l2(0.01),\n",
    "              name='hidden_layer'),\n",
    "        Dropout(0.2, name='dropout'),\n",
    "        Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "    \n",
    "    # Compilar modelo\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                 keras.metrics.Precision(name='precision'),\n",
    "                 keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Criar modelo\n",
    "model = criar_mlp1(input_dim=X_train.shape[1])\n",
    "\n",
    "# Resumo da arquitetura\n",
    "print(\"=\"*70)\n",
    "print(\"üèóÔ∏è ARQUITETURA MLP 1 - MINIMALISTA\")\n",
    "print(\"=\"*70)\n",
    "model.summary()\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525457aa",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configurar Hiperpar√¢metros e Callbacks\n",
    "\n",
    "**Hiperpar√¢metros escolhidos:**\n",
    "- **Learning Rate:** 0.001 (padr√£o Adam, funciona bem para maioria dos casos)\n",
    "- **Batch Size:** 32 (equil√≠brio entre estabilidade e velocidade)\n",
    "- **Epochs:** 200 (com Early Stopping para evitar overfitting)\n",
    "\n",
    "**Callbacks:**\n",
    "- **EarlyStopping:** Para se val_loss n√£o melhorar por 20 epochs\n",
    "- **ModelCheckpoint:** Salva melhor modelo (menor val_loss)\n",
    "- **ReduceLROnPlateau:** Reduz learning rate se val_loss estagnar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperpar√¢metros\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='../artifacts/mlp1_best_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Hiperpar√¢metros configurados:\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   - Epochs: {EPOCHS}\")\n",
    "print(f\"   - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   - Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e1899",
   "metadata": {},
   "source": [
    "## üöÄ Treinar Modelo\n",
    "\n",
    "Iniciamos o treinamento com valida√ß√£o cont√≠nua para monitorar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Iniciando treinamento...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ Treinamento completo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204edc6",
   "metadata": {},
   "source": [
    "## üìä Visualizar Curvas de Aprendizado\n",
    "\n",
    "Analisamos Loss e Acur√°cia para detectar overfitting/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('MLP 1 - Loss por Epoch', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Acur√°cia\n",
    "axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('MLP 1 - Acur√°cia por Epoch', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/mlp1_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°ficos salvos em: reports/figures/mlp1_learning_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e834a",
   "metadata": {},
   "source": [
    "## üéØ Avaliar Performance no Conjunto de Valida√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√µes\n",
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).ravel()\n",
    "\n",
    "# M√©tricas\n",
    "val_accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä M√âTRICAS DE VALIDA√á√ÉO - MLP 1\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüéØ Acur√°cia: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_val, y_pred, target_names=['Morreu (0)', 'Sobreviveu (1)']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b386a9",
   "metadata": {},
   "source": [
    "## üîç Matriz de Confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Morreu (0)', 'Sobreviveu (1)'],\n",
    "            yticklabels=['Morreu (0)', 'Sobreviveu (1)'],\n",
    "            cbar_kws={'label': 'Quantidade'})\n",
    "plt.xlabel('Predi√ß√£o', fontsize=12)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.title('MLP 1 - Matriz de Confus√£o (Valida√ß√£o)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/mlp1_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Matriz de confus√£o salva em: reports/figures/mlp1_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63366eca",
   "metadata": {},
   "source": [
    "## üíæ Salvar M√©tricas e Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7adb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar hist√≥rico de treino\n",
    "history_dict = {\n",
    "    'loss': [float(x) for x in history.history['loss']],\n",
    "    'val_loss': [float(x) for x in history.history['val_loss']],\n",
    "    'accuracy': [float(x) for x in history.history['accuracy']],\n",
    "    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
    "    'precision': [float(x) for x in history.history['precision']],\n",
    "    'val_precision': [float(x) for x in history.history['val_precision']],\n",
    "    'recall': [float(x) for x in history.history['recall']],\n",
    "    'val_recall': [float(x) for x in history.history['val_recall']]\n",
    "}\n",
    "\n",
    "with open('../reports/mlp1_history.json', 'w') as f:\n",
    "    json.dump(history_dict, f, indent=4)\n",
    "\n",
    "# Salvar m√©tricas finais\n",
    "metrics = {\n",
    "    'model_name': 'MLP1_Minimalista',\n",
    "    'architecture': 'Input(15) -> Dense(16, ReLU) -> Output(1, Sigmoid)',\n",
    "    'total_params': 273,\n",
    "    'trainable_params': 273,\n",
    "    'hyperparameters': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_run': len(history.history['loss']),\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'dropout': 0.2,\n",
    "        'l2_regularization': 0.01\n",
    "    },\n",
    "    'val_metrics': {\n",
    "        'accuracy': float(val_accuracy),\n",
    "        'final_val_loss': float(history.history['val_loss'][-1]),\n",
    "        'best_val_loss': float(min(history.history['val_loss'])),\n",
    "        'best_val_accuracy': float(max(history.history['val_accuracy']))\n",
    "    },\n",
    "    'confusion_matrix': cm.tolist()\n",
    "}\n",
    "\n",
    "with open('../reports/mlp1_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Salvar modelo final\n",
    "model.save('../artifacts/mlp1_final_model.keras')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üíæ ARQUIVOS SALVOS\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ Modelo: artifacts/mlp1_best_model.keras (melhor val_loss)\")\n",
    "print(\"‚úÖ Modelo: artifacts/mlp1_final_model.keras (final)\")\n",
    "print(\"‚úÖ Hist√≥rico: reports/mlp1_history.json\")\n",
    "print(\"‚úÖ M√©tricas: reports/mlp1_metrics.json\")\n",
    "print(\"‚úÖ Gr√°ficos: reports/figures/mlp1_*.png\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016aff28",
   "metadata": {},
   "source": [
    "## üéâ RESUMO FINAL - MLP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ SEMANA 2 COMPLETA - MLP 1 MINIMALISTA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "‚úÖ Arquitetura implementada: Input(15) ‚Üí Dense(16) ‚Üí Output(1)\n",
    "‚úÖ Total de par√¢metros: 273\n",
    "‚úÖ Rela√ß√£o amostras/par√¢metros: {712/273:.2f}\n",
    "\n",
    "üìä RESULTADOS:\n",
    "   - Acur√°cia Valida√ß√£o: {val_accuracy*100:.2f}%\n",
    "   - Melhor Val Loss: {min(history.history['val_loss']):.4f}\n",
    "   - Melhor Val Accuracy: {max(history.history['val_accuracy'])*100:.2f}%\n",
    "   - Epochs executados: {len(history.history['loss'])}\n",
    "\n",
    "üìà AN√ÅLISE:\n",
    "   - Baseline estabelecido com sucesso\n",
    "   - Modelo simples e interpret√°vel\n",
    "   - Baixo risco de overfitting confirmado\n",
    "\n",
    "üéØ PR√ìXIMOS PASSOS:\n",
    "   - Semana 3: Implementar MLP 2 (Moderada) ou Ensemble 3\n",
    "   - Comparar performance entre arquiteturas\n",
    "   - Decidir melhor modelo para produ√ß√£o\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
