# 4 PROPOSTAS DE ARQUITETURAS - TITANIC DATASET

**Dataset:** 891 amostras Ã— 15 features  
**Problema:** ClassificaÃ§Ã£o binÃ¡ria (sobreviveu: 0 ou 1)  
**Desafio:** Poucos dados = alto risco de overfitting

---

## ğŸ¯ ESTRATÃ‰GIA GERAL

**2 TIPOS de abordagem:**
- **TIPO A - MLP (Multi-Layer Perceptron):** Rede Ãºnica com camadas densas
- **TIPO B - ENSEMBLE:** MÃºltiplas redes pequenas votando juntas

**Cada tipo terÃ¡ 2 variaÃ§Ãµes** = 4 caminhos totais

**Regra:** Com 891 amostras, limite conservador = ~300 parÃ¢metros (cada parÃ¢metro vÃª ~3 exemplos)

---

# TIPO A - MLP (Multi-Layer Perceptron)

## ğŸ“Š ARQUITETURA 1: MLP MINIMALISTA

**Estrutura:**
```
Input (15) â†’ Dense(16, ReLU) â†’ Output(1, Sigmoid)
```

**ParÃ¢metros:**
- Camada 1: 15 Ã— 16 + 16 = 256
- Camada 2: 16 Ã— 1 + 1 = 17
- **TOTAL: 273 parÃ¢metros**

**Justificativa:**
- âœ… RelaÃ§Ã£o 891/273 = **3.26 amostras por parÃ¢metro** (seguro!)
- âœ… Apenas 1 camada oculta = menos risco de overfitting
- âœ… 16 neurÃ´nios suficientes para capturar padrÃµes principais (Sex, Pclass, Age, FamilySize)
- âœ… Arquitetura mais **simples e interpretÃ¡vel**

**Por que essa escolha?**
Com poucos dados, simplicidade Ã© vantagem. Esta rede aprende apenas padrÃµes essenciais sem decorar ruÃ­dos.

**TÃ©cnicas anti-overfitting:**
- Dropout: 0.2 (desliga 20% dos neurÃ´nios no treino)
- L2 Regularization: 0.01 (penaliza pesos grandes)

**PrevisÃ£o de performance:** 80-82% acurÃ¡cia

---

## ğŸ“Š ARQUITETURA 2: MLP MODERADA

**Estrutura:**
```
Input (15) â†’ Dense(32, ReLU) â†’ Dense(16, ReLU) â†’ Output(1, Sigmoid)
```

**ParÃ¢metros:**
- Camada 1: 15 Ã— 32 + 32 = 512
- Camada 2: 32 Ã— 16 + 16 = 528
- Camada 3: 16 Ã— 1 + 1 = 17
- **TOTAL: 1057 parÃ¢metros**

**Justificativa:**
- âš ï¸ RelaÃ§Ã£o 891/1057 = **0.84 amostras por parÃ¢metro** (RISCO!)
- âœ… 2 camadas ocultas = pode capturar **interaÃ§Ãµes nÃ£o-lineares** entre features
- âœ… Arquitetura "afunilada" (32â†’16â†’1) = compressÃ£o progressiva de informaÃ§Ã£o
- âš ï¸ PRECISA de Dropout/RegularizaÃ§Ã£o forte para funcionar

**Por que essa escolha?**
Testa se padrÃµes mais complexos existem nos dados. Se houver interaÃ§Ãµes sutis (ex: "mulheres de 1Âª classe COM famÃ­lia pequena"), essa rede pode capturar.

**TÃ©cnicas anti-overfitting (OBRIGATÃ“RIAS):**
- Dropout: 0.4 nas camadas (desliga 40% dos neurÃ´nios)
- L2 Regularization: 0.02
- Early Stopping: para treino se validaÃ§Ã£o nÃ£o melhorar por 20 epochs

**PrevisÃ£o de performance:** 79-83% acurÃ¡cia (alta variÃ¢ncia - pode overfitar OU superar a MLP 1)

---

# TIPO B - ENSEMBLE NEURAL

**Conceito:** Ao invÃ©s de 1 rede grande, treinar **vÃ¡rias redes pequenas** com:
- InicializaÃ§Ãµes aleatÃ³rias diferentes
- Subsets ligeiramente diferentes dos dados (bagging)
- Arquiteturas levemente variadas

**DecisÃ£o final:** VotaÃ§Ã£o por maioria ou mÃ©dia das probabilidades

**Por que Ensemble reduz overfitting?**
- Cada rede "decora" coisas diferentes
- Erros individuais se cancelam na votaÃ§Ã£o
- Aumenta robustez e confiabilidade

---

## ğŸ“Š ARQUITETURA 3: ENSEMBLE CONSERVADOR

**Estrutura:** 3 redes idÃªnticas com inicializaÃ§Ãµes diferentes

**Cada rede:**
```
Input (15) â†’ Dense(12, ReLU) â†’ Output(1, Sigmoid)
```

**ParÃ¢metros POR REDE:**
- Camada 1: 15 Ã— 12 + 12 = 192
- Camada 2: 12 Ã— 1 + 1 = 13
- **Por rede: 205 parÃ¢metros**

**TOTAL ENSEMBLE: 3 Ã— 205 = 615 parÃ¢metros**

**Justificativa:**
- âœ… Cada rede individual Ã© PEQUENA (205 params)
- âœ… 3 redes = equilÃ­brio entre diversidade e custo computacional
- âœ… VotaÃ§Ã£o reduz overfitting individual de cada rede
- âœ… Mais robusto que MLP 1, mas ainda conservador

**Como funciona a votaÃ§Ã£o:**
```python
Rede 1: 0.82 (sobrevive)
Rede 2: 0.45 (morre)
Rede 3: 0.78 (sobrevive)
MÃ‰DIA: 0.68 â†’ SOBREVIVE âœ…
```

**TÃ©cnicas anti-overfitting:**
- Bagging: cada rede treina com 80% dos dados (aleatÃ³rio)
- Dropout: 0.3
- L2 Regularization: 0.01

**PrevisÃ£o de performance:** 81-83% acurÃ¡cia (mais estÃ¡vel que MLPs)

---

## ğŸ“Š ARQUITETURA 4: ENSEMBLE DIVERSIFICADO

**Estrutura:** 5 redes com ARQUITETURAS VARIADAS

**Rede 1 (Linear):**
```
Input (15) â†’ Dense(8, ReLU) â†’ Output(1, Sigmoid)
ParÃ¢metros: 129
```

**Rede 2 (Moderada):**
```
Input (15) â†’ Dense(16, ReLU) â†’ Dense(8, ReLU) â†’ Output(1, Sigmoid)
ParÃ¢metros: 409
```

**Rede 3 (Wide):**
```
Input (15) â†’ Dense(20, ReLU) â†’ Output(1, Sigmoid)
ParÃ¢metros: 321
```

**Rede 4 (Deep Narrow):**
```
Input (15) â†’ Dense(10, ReLU) â†’ Dense(10, ReLU) â†’ Dense(8, ReLU) â†’ Output(1, Sigmoid)
ParÃ¢metros: 339
```

**Rede 5 (Dropout Heavy):**
```
Input (15) â†’ Dense(12, ReLU) â†’ Dropout(0.5) â†’ Dense(12, ReLU) â†’ Output(1, Sigmoid)
ParÃ¢metros: 349
```

**TOTAL ENSEMBLE: 1547 parÃ¢metros** (mas distribuÃ­dos!)

**Justificativa:**
- âœ… **DIVERSIDADE MÃXIMA:** cada rede tem viÃ©s diferente
- âœ… Rede 1 captura padrÃµes simples/lineares
- âœ… Rede 2 captura interaÃ§Ãµes moderadas
- âœ… Rede 3 tenta memorizar mais (mas serÃ¡ "corrigida" pelas outras)
- âœ… Rede 4 busca padrÃµes profundos
- âœ… Rede 5 Ã© extremamente regularizada
- âœ… VotaÃ§Ã£o de 5 Ã© mais robusta que 3

**Por que essa escolha?**
Filosofia: "nÃ£o sabemos qual padrÃ£o funciona melhor, entÃ£o testamos TODOS simultaneamente". A votaÃ§Ã£o escolhe o melhor coletivamente.

**Como funciona a votaÃ§Ã£o:**
```python
Rede 1: 0.45 (morre)
Rede 2: 0.78 (sobrevive)
Rede 3: 0.92 (sobrevive)
Rede 4: 0.55 (sobrevive)
Rede 5: 0.41 (morre)
MÃ‰DIA: 0.62 â†’ SOBREVIVE âœ…
```

**TÃ©cnicas anti-overfitting:**
- Bagging: cada rede treina com subset diferente
- Dropout variÃ¡vel (0.3 a 0.5)
- L2 Regularization: 0.01-0.02
- Early Stopping individual por rede

**PrevisÃ£o de performance:** 82-84% acurÃ¡cia (mais alto potencial, mas mais complexo)

---

# ğŸ“‹ COMPARAÃ‡ÃƒO RESUMIDA

| Arquitetura | ParÃ¢metros | Amostras/Param | Risco Overfit | Complexidade | AcurÃ¡cia Esperada |
|-------------|------------|----------------|---------------|--------------|-------------------|
| **MLP 1 - Minimalista** | 273 | 3.26 | ğŸŸ¢ BAIXO | Simples | 80-82% |
| **MLP 2 - Moderada** | 1057 | 0.84 | ğŸ”´ ALTO | MÃ©dia | 79-83% |
| **Ensemble 3 - Conservador** | 615 | 1.45 | ğŸŸ¡ MÃ‰DIO | MÃ©dia | 81-83% |
| **Ensemble 4 - Diversificado** | 1547 | 0.58 | ğŸŸ¡ MÃ‰DIO | Alta | 82-84% |

---

# ğŸ¯ RECOMENDAÃ‡ÃƒO PARA DEBATE

**ORDEM DE TESTE:**

1ï¸âƒ£ **MLP 1 (Minimalista)** â†’ Baseline simples e seguro  
2ï¸âƒ£ **Ensemble 3 (Conservador)** â†’ Teste se ensemble vale a pena  
3ï¸âƒ£ **Ensemble 4 (Diversificado)** â†’ MÃ¡ximo potencial, aceita risco  
4ï¸âƒ£ **MLP 2 (Moderada)** â†’ SÃ³ testar se os outros decepcionar (alto risco)

---

# ğŸ’¡ PONTOS PARA DISCUTIR COM O PROFESSOR

**1. Trade-off Bias-Variance:**
- MLP 1 = alto bias, baixa variance (underfitting leve, mas estÃ¡vel)
- MLP 2 = baixo bias, alta variance (pode overfitar)
- Ensembles = equilibram bias-variance naturalmente

**2. Por que 2 MLPs e 2 Ensembles?**
- MLPs: para entender se complexidade ajuda ou atrapalha
- Ensembles: para entender se diversidade Ã© melhor que profundidade

**3. Justificativa estatÃ­stica:**
- 891 amostras / 273 params = cada peso vÃª 3+ exemplos âœ…
- 891 amostras / 1057 params = cada peso vÃª <1 exemplo âš ï¸

**4. Porque Ensemble pode usar mais parÃ¢metros totais?**
- ParÃ¢metros estÃ£o **distribuÃ­dos** em redes independentes
- Cada rede individualmente Ã© pequena
- VotaÃ§Ã£o cancela overfitting individual

**5. Experimento controlado:**
- Treinar as 4 arquiteturas com MESMOS dados
- Comparar curvas de learning (train vs validation loss)
- Analisar onde cada uma overfitta

---

# ğŸš€ PRÃ“XIMOS PASSOS

ApÃ³s escolher 1 das 4:

1. Implementar em Keras/TensorFlow
2. Treinar com validaÃ§Ã£o cruzada (k-fold)
3. Plotar curvas de aprendizado
4. Comparar com baseline (Random Forest do chat anterior = 81-83%)
5. Escolher hiperparÃ¢metros finais
6. Testar no conjunto de teste

---

**Documento criado para projeto de ML - Dataset Titanic**  
*Data: 31 de Outubro de 2025*
